{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,  accuracy_score\n",
    "\n",
    "def plot_gallery(images): \n",
    "    \n",
    "    # Affiche les 12 premières images contenues dans images\n",
    "    # images est de taille Nb image*Ny*Nx \n",
    "    plt.figure(figsize=(7.2, 7.2)) \n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35) \n",
    "    for i in range(12): \n",
    "        plt.subplot(3, 4, i + 1) \n",
    "        plt.imshow(images[i], cmap=plt.cm.gray) \n",
    "        plt.xticks(()) \n",
    "        plt.yticks(()) \n",
    "        plt.show()\n",
    "[X, y, name]=np.load(\"TP1.npy\",allow_pickle=True )\n",
    "    \n",
    "#charger les données\n",
    "plot_gallery(X) #afficher les images\n",
    "\n",
    "print(X.shape) #taille de limage 62*47\n",
    "print(max(y)) #/le nombre de classes\n",
    "print(name)   #identité des personnes\n",
    "plt.hist(y,bins=7,range=[0,7])   #histogramme\n",
    "\n",
    "#partitionnement de la base d'apprentissage\n",
    "\n",
    "#repartition des données en donnee d'apprentissage et test\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.25, random_state=42) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Redimensionnement des données \n",
    "# pour passer d'une image représenté en 2D à une image 1D\n",
    "# n=2914=62*47\n",
    "\n",
    "X_train=np.reshape(X_train,[X_train.shape[0],2914])\n",
    "X_test=np.reshape(X_test,[X_test.shape[0],2914])\n",
    "\n",
    "\n",
    "# Mise en forme des données pour la classification\n",
    "# donnees d'apprentissage\n",
    "scaler1=StandardScaler()\n",
    "scaler1.fit(X_train)  # pour la calcul de la moyenne et la variance\n",
    "print(scaler1.mean_)  # moyenne\n",
    "print(scaler1.var_)   # variance\n",
    "\n",
    "X_train=scaler1.transform(X_train)  #normalisation des données\n",
    "\n",
    "#données de test\n",
    "scaler2=StandardScaler()\n",
    "scaler2.fit(X_test)   # pour la calcul de la moyenne et la variance\n",
    "print(scaler2.mean_)  # moyenne\n",
    "print(scaler2.var_)   # variance\n",
    "\n",
    "X_test=scaler2.transform(X_test)  #normalisation des données\n",
    "\n",
    "# Classifieur 1PPV\n",
    "#classifieur=KNeighboursClassifier(n_neighbours=...,p=1 ou 2) p=1 dist euclidienne p=2 dist de manhattan\n",
    "\n",
    "classifieur=KNeighborsClassifier(n_neighbors=1,p=1)\n",
    "classifieur.fit(X_train,y_train)\n",
    "y_pred=classifieur.predict(X_test)\n",
    "\n",
    "mat=confusion_matrix(y_test,y_pred) #matrice de confusion\n",
    "\n",
    "#taux de reconnaissance à partir des éléments de la mat de confusion  \n",
    "# accuracy = somme des elements de la diagonnale (trace) / somme de tt les elements\n",
    "# deux façon de calculer l'accuracy\n",
    "acc1=np.sum(np.diag(mat))/np.sum(mat)\n",
    "acc2=accuracy_score(y_test,y_pred)\n",
    "print(acc1,acc2)\n",
    "plt.hist(y_pred,bins=7,range=[0,7])   #histogramme permet de voir si les classes sont équilibrées ou nn\n",
    "# d'apres l'histogramme les classes ne sont pas equilibréesla classe 3 est representée plus que les autres\n",
    " \n",
    "# la matrice de confusion represente comment les donnees ont été predites\n",
    "# la somme de la matrice de confusion represente le nombre d'images de test\n",
    "\n",
    "# Classifieur KPPV\n",
    "for k in range(1,10):\n",
    "    classifieur=KNeighborsClassifier(n_neighbors=k,p=1)\n",
    "    classifieur.fit(X_train,y_train)\n",
    "    y_pred=classifieur.predict(X_test)\n",
    "    mat=confusion_matrix(y_test,y_pred) \n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    \n",
    "# Classifieur KPPV et distance de Manhattan\n",
    "for k in range(1,10):\n",
    "    classifieur=KNeighborsClassifier(n_neighbors=k,p=2)\n",
    "    classifieur.fit(X_train,y_train)\n",
    "    y_pred=classifieur.predict(X_test)\n",
    "    mat=confusion_matrix(y_test,y_pred) \n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
